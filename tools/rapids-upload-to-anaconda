#!/bin/bash
# A utility script that uploads all the conda packages from a
# GitHub Actions workflow run to Anaconda.org
set -euo pipefail
source rapids-constants
export RAPIDS_SCRIPT_NAME="rapids-upload-to-anaconda"

case "${RAPIDS_BUILD_TYPE}" in
  branch)
    ;&
  nightly)
    ;;
  *)
    rapids-echo-stderr "Only branch builds and nightly builds are uploaded to Anaconda.org"
    exit 1
    ;;
esac


S3_PATH=$(rapids-s3-path)
BUCKET_PREFIX=${S3_PATH/s3:\/\/${RAPIDS_DOWNLOADS_BUCKET}\//} # removes s3://rapids-downloads/ from s3://rapids-downloads/ci/rmm/...

# shellcheck disable=SC2016
CONDA_ARTIFACTS=$(
  set -eo pipefail;
  aws \
    --output json \
    s3api list-objects \
    --bucket "${RAPIDS_DOWNLOADS_BUCKET}" \
    --prefix "${BUCKET_PREFIX}" \
    --page-size 100 \
    --query 'Contents[?contains(Key, `conda`)].Key' \
    | jq -c
)
export CONDA_ARTIFACTS

for OBJ in $(jq -nr 'env.CONDA_ARTIFACTS | fromjson | .[]'); do
  FILENAME=$(basename "${OBJ}")
  FILENAME_NO_EXT="${FILENAME%%.*}"
  S3_URI="${S3_PATH}${FILENAME}"
  UNTAR_DEST="${FILENAME_NO_EXT}"

  rapids-echo-stderr "Untarring ${S3_URI} into ${UNTAR_DEST}"
  mkdir -p "${UNTAR_DEST}"
  aws s3 cp --only-show-errors "${S3_URI}" - | tar xzf - -C "${UNTAR_DEST}"

  PKGS_TO_UPLOAD=$(rapids-find-anaconda-uploads.py "${UNTAR_DEST}")

  if [ -z "${PKGS_TO_UPLOAD}" ]; then
    rapids-echo-stderr "Couldn't find any packages to upload in: ${UNTAR_DEST}"
    ls -l "${UNTAR_DEST}/"*
    continue
  fi

  rapids-echo-stderr "Uploading packages to Anaconda.org: ${PKGS_TO_UPLOAD}"

  export RAPIDS_RETRY_SLEEP=180
  # shellcheck disable=SC2086
  rapids-retry anaconda \
    -t "${RAPIDS_CONDA_TOKEN}" \
    upload \
    --label "${RAPIDS_CONDA_UPLOAD_LABEL:-main}" \
    --skip-existing \
    --no-progress \
    ${PKGS_TO_UPLOAD}

  if [ -d telemetry-artifacts ]; then
    ls -l "${UNTAR_DEST}"/*.tar.bz2 >> telemetry-artifacts/artifact-list.txt
    ls -l "${UNTAR_DEST}"/*.conda >> telemetry-artifacts/artifact-list.txt
  fi

  echo ""
done
